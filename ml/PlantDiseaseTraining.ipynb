{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# ðŸŒ± Plant Disease Detection - Model Training\n",
                "\n",
                "This notebook trains a custom CNN model for plant disease detection using:\n",
                "- **MobileNetV2** (Transfer Learning)\n",
                "- **PlantVillage Dataset** (87,000+ images, 38 classes)\n",
                "- **TensorFlow.js Export** for browser deployment\n",
                "\n",
                "---\n",
                "\n",
                "## âš¡ Before Starting\n",
                "1. Go to **Runtime > Change runtime type**\n",
                "2. Select **GPU** as Hardware accelerator (T4 is fine)\n",
                "3. Click **Save**\n",
                "\n",
                "---"
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 1: Install Dependencies"
            ],
            "metadata": {
                "id": "step1"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install"
            },
            "outputs": [],
            "source": [
                "!pip install tensorflow tensorflow-datasets tensorflowjs pillow -q\n",
                "print(\"âœ… Dependencies installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 2: Check GPU Availability"
            ],
            "metadata": {
                "id": "step2"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import tensorflow as tf\n",
                "\n",
                "gpus = tf.config.list_physical_devices('GPU')\n",
                "if gpus:\n",
                "    print(f\"âœ… GPU detected: {gpus[0].name}\")\n",
                "    print(f\"   TensorFlow version: {tf.__version__}\")\n",
                "else:\n",
                "    print(\"âŒ No GPU detected! Go to Runtime > Change runtime type > GPU\")"
            ],
            "metadata": {
                "id": "check_gpu"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 3: Define Disease Classes (38 total)"
            ],
            "metadata": {
                "id": "step3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "CLASS_LABELS = [\n",
                "    \"Apple___Apple_scab\",\n",
                "    \"Apple___Black_rot\",\n",
                "    \"Apple___Cedar_apple_rust\",\n",
                "    \"Apple___healthy\",\n",
                "    \"Blueberry___healthy\",\n",
                "    \"Cherry_(including_sour)___Powdery_mildew\",\n",
                "    \"Cherry_(including_sour)___healthy\",\n",
                "    \"Corn_(maize)___Cercospora_leaf_spot_Gray_leaf_spot\",\n",
                "    \"Corn_(maize)___Common_rust_\",\n",
                "    \"Corn_(maize)___Northern_Leaf_Blight\",\n",
                "    \"Corn_(maize)___healthy\",\n",
                "    \"Grape___Black_rot\",\n",
                "    \"Grape___Esca_(Black_Measles)\",\n",
                "    \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
                "    \"Grape___healthy\",\n",
                "    \"Orange___Haunglongbing_(Citrus_greening)\",\n",
                "    \"Peach___Bacterial_spot\",\n",
                "    \"Peach___healthy\",\n",
                "    \"Pepper,_bell___Bacterial_spot\",\n",
                "    \"Pepper,_bell___healthy\",\n",
                "    \"Potato___Early_blight\",\n",
                "    \"Potato___Late_blight\",\n",
                "    \"Potato___healthy\",\n",
                "    \"Raspberry___healthy\",\n",
                "    \"Soybean___healthy\",\n",
                "    \"Squash___Powdery_mildew\",\n",
                "    \"Strawberry___Leaf_scorch\",\n",
                "    \"Strawberry___healthy\",\n",
                "    \"Tomato___Bacterial_spot\",\n",
                "    \"Tomato___Early_blight\",\n",
                "    \"Tomato___Late_blight\",\n",
                "    \"Tomato___Leaf_Mold\",\n",
                "    \"Tomato___Septoria_leaf_spot\",\n",
                "    \"Tomato___Spider_mites_Two-spotted_spider_mite\",\n",
                "    \"Tomato___Target_Spot\",\n",
                "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
                "    \"Tomato___Tomato_mosaic_virus\",\n",
                "    \"Tomato___healthy\"\n",
                "]\n",
                "\n",
                "NUM_CLASSES = len(CLASS_LABELS)\n",
                "IMG_SIZE = 224\n",
                "BATCH_SIZE = 32\n",
                "\n",
                "print(f\"âœ… {NUM_CLASSES} disease classes defined\")"
            ],
            "metadata": {
                "id": "classes"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 4: Load PlantVillage Dataset\n",
                "\n",
                "This downloads ~1.2GB of plant leaf images (may take 5-10 minutes)"
            ],
            "metadata": {
                "id": "step4"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import tensorflow_datasets as tfds\n",
                "\n",
                "print(\"ðŸ“¥ Downloading PlantVillage dataset (this may take a few minutes)...\")\n",
                "\n",
                "# Load dataset\n",
                "(train_ds, val_ds), info = tfds.load(\n",
                "    'plant_village',\n",
                "    split=['train[:80%]', 'train[80%:]'],\n",
                "    with_info=True,\n",
                "    as_supervised=True\n",
                ")\n",
                "\n",
                "print(f\"\\nâœ… Dataset loaded!\")\n",
                "print(f\"   Total images: {info.splits['train'].num_examples:,}\")\n",
                "print(f\"   Training: ~{int(info.splits['train'].num_examples * 0.8):,}\")\n",
                "print(f\"   Validation: ~{int(info.splits['train'].num_examples * 0.2):,}\")"
            ],
            "metadata": {
                "id": "load_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 5: Preprocess and Augment Data"
            ],
            "metadata": {
                "id": "step5"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from tensorflow.keras import layers\n",
                "\n",
                "# Data augmentation for training\n",
                "data_augmentation = tf.keras.Sequential([\n",
                "    layers.RandomFlip(\"horizontal\"),\n",
                "    layers.RandomRotation(0.2),\n",
                "    layers.RandomZoom(0.2),\n",
                "    layers.RandomContrast(0.2),\n",
                "])\n",
                "\n",
                "def preprocess_train(image, label):\n",
                "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
                "    image = tf.cast(image, tf.float32) / 255.0\n",
                "    image = data_augmentation(image, training=True)\n",
                "    label = tf.one_hot(label, NUM_CLASSES)\n",
                "    return image, label\n",
                "\n",
                "def preprocess_val(image, label):\n",
                "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
                "    image = tf.cast(image, tf.float32) / 255.0\n",
                "    label = tf.one_hot(label, NUM_CLASSES)\n",
                "    return image, label\n",
                "\n",
                "# Apply preprocessing\n",
                "train_ds = train_ds.map(preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "train_ds = train_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
                "\n",
                "val_ds = val_ds.map(preprocess_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
                "\n",
                "print(\"âœ… Data preprocessing configured!\")"
            ],
            "metadata": {
                "id": "preprocess"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 6: Build Model (MobileNetV2 + Custom Head)"
            ],
            "metadata": {
                "id": "step6"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from tensorflow.keras.applications import MobileNetV2\n",
                "from tensorflow.keras import Model\n",
                "\n",
                "# Load pre-trained MobileNetV2\n",
                "base_model = MobileNetV2(\n",
                "    weights='imagenet',\n",
                "    include_top=False,\n",
                "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
                ")\n",
                "\n",
                "# Freeze base model\n",
                "base_model.trainable = False\n",
                "\n",
                "# Build model\n",
                "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
                "x = base_model(inputs, training=False)\n",
                "x = layers.GlobalAveragePooling2D()(x)\n",
                "x = layers.Dense(256, activation='relu')(x)\n",
                "x = layers.Dropout(0.5)(x)\n",
                "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
                "\n",
                "model = Model(inputs, outputs)\n",
                "\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
                "    loss='categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "print(\"\\nâœ… Model built!\")\n",
                "print(f\"   Total params: {model.count_params():,}\")\n",
                "print(f\"   Trainable params: {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}\")"
            ],
            "metadata": {
                "id": "build_model"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 7: Train - Phase 1 (Transfer Learning)\n",
                "\n",
                "Training with frozen base model (takes ~15-20 minutes with GPU)"
            ],
            "metadata": {
                "id": "step7"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"ðŸš€ Phase 1: Transfer Learning (frozen base)\")\n",
                "print(\"   This will take ~15-20 minutes...\\n\")\n",
                "\n",
                "callbacks = [\n",
                "    tf.keras.callbacks.EarlyStopping(\n",
                "        monitor='val_loss',\n",
                "        patience=3,\n",
                "        restore_best_weights=True\n",
                "    ),\n",
                "    tf.keras.callbacks.ReduceLROnPlateau(\n",
                "        monitor='val_loss',\n",
                "        factor=0.2,\n",
                "        patience=2\n",
                "    )\n",
                "]\n",
                "\n",
                "history1 = model.fit(\n",
                "    train_ds,\n",
                "    epochs=10,\n",
                "    validation_data=val_ds,\n",
                "    callbacks=callbacks\n",
                ")\n",
                "\n",
                "print(f\"\\nâœ… Phase 1 Complete!\")\n",
                "print(f\"   Best validation accuracy: {max(history1.history['val_accuracy']):.2%}\")"
            ],
            "metadata": {
                "id": "train_phase1"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 8: Train - Phase 2 (Fine-Tuning)\n",
                "\n",
                "Unfreeze last 20 layers and train with lower learning rate"
            ],
            "metadata": {
                "id": "step8"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"ðŸŽ¯ Phase 2: Fine-tuning (last 20 layers)\")\n",
                "print(\"   This will take ~10-15 minutes...\\n\")\n",
                "\n",
                "# Unfreeze base model\n",
                "base_model.trainable = True\n",
                "\n",
                "# Freeze all layers except last 20\n",
                "for layer in base_model.layers[:-20]:\n",
                "    layer.trainable = False\n",
                "\n",
                "# Recompile with lower learning rate\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
                "    loss='categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "history2 = model.fit(\n",
                "    train_ds,\n",
                "    epochs=5,\n",
                "    validation_data=val_ds,\n",
                "    callbacks=callbacks\n",
                ")\n",
                "\n",
                "print(f\"\\nâœ… Phase 2 Complete!\")\n",
                "print(f\"   Final validation accuracy: {max(history2.history['val_accuracy']):.2%}\")"
            ],
            "metadata": {
                "id": "train_phase2"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 9: Save Model"
            ],
            "metadata": {
                "id": "step9"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "\n",
                "os.makedirs('saved_model', exist_ok=True)\n",
                "\n",
                "# Save in Keras format\n",
                "model.save('saved_model/plant_disease_model.keras')\n",
                "print(\"âœ… Model saved: saved_model/plant_disease_model.keras\")\n",
                "\n",
                "# Save in H5 format for TensorFlow.js conversion\n",
                "model.save('saved_model/plant_disease_model.h5')\n",
                "print(\"âœ… H5 saved: saved_model/plant_disease_model.h5\")"
            ],
            "metadata": {
                "id": "save_model"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 10: Export to TensorFlow.js"
            ],
            "metadata": {
                "id": "step10"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import subprocess\n",
                "\n",
                "os.makedirs('tfjs_model', exist_ok=True)\n",
                "\n",
                "print(\"ðŸ“¦ Converting to TensorFlow.js format...\")\n",
                "\n",
                "!tensorflowjs_converter \\\n",
                "    --input_format=keras \\\n",
                "    --output_format=tfjs_layers_model \\\n",
                "    saved_model/plant_disease_model.h5 \\\n",
                "    tfjs_model/\n",
                "\n",
                "print(\"\\nâœ… TensorFlow.js model created!\")\n",
                "print(\"   Files in tfjs_model/:\")\n",
                "for f in os.listdir('tfjs_model'):\n",
                "    size = os.path.getsize(f'tfjs_model/{f}')\n",
                "    print(f\"   - {f}: {size/1024:.1f} KB\")"
            ],
            "metadata": {
                "id": "export_tfjs"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 11: Create Labels JSON"
            ],
            "metadata": {
                "id": "step11"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import json\n",
                "\n",
                "labels_dict = {}\n",
                "for i, label in enumerate(CLASS_LABELS):\n",
                "    parts = label.split(\"___\")\n",
                "    crop = parts[0].replace(\"_\", \" \")\n",
                "    condition = parts[1].replace(\"_\", \" \") if len(parts) > 1 else \"Unknown\"\n",
                "    friendly_name = f\"{crop} - {condition}\".title()\n",
                "    \n",
                "    labels_dict[str(i)] = {\n",
                "        \"name\": friendly_name,\n",
                "        \"crop\": crop,\n",
                "        \"condition\": condition\n",
                "    }\n",
                "\n",
                "with open('tfjs_model/labels.json', 'w') as f:\n",
                "    json.dump(labels_dict, f, indent=2)\n",
                "\n",
                "print(\"âœ… Labels saved: tfjs_model/labels.json\")\n",
                "print(f\"   {len(labels_dict)} classes\")"
            ],
            "metadata": {
                "id": "create_labels"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Step 12: Download Model Files\n",
                "\n",
                "Download the `tfjs_model.zip` and extract to your project's `frontend/public/models/plant-disease/` folder"
            ],
            "metadata": {
                "id": "step12"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import shutil\n",
                "from google.colab import files\n",
                "\n",
                "# Create zip file\n",
                "shutil.make_archive('tfjs_model', 'zip', 'tfjs_model')\n",
                "\n",
                "print(\"ðŸ“¥ Downloading tfjs_model.zip...\")\n",
                "print(\"\\nAfter download:\")\n",
                "print(\"1. Extract the zip file\")\n",
                "print(\"2. Copy all files to: frontend/public/models/plant-disease/\")\n",
                "print(\"3. Run your app and select 'Custom Model' in Settings!\")\n",
                "\n",
                "files.download('tfjs_model.zip')"
            ],
            "metadata": {
                "id": "download"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "\n",
                "## ðŸŽ‰ Training Complete!\n",
                "\n",
                "### Next Steps:\n",
                "1. Download `tfjs_model.zip` (should auto-download above)\n",
                "2. Extract to `frontend/public/models/plant-disease/`\n",
                "3. Run `npm install` in your project\n",
                "4. Run `npm run dev`\n",
                "5. Go to Settings â†’ Select \"Custom Model (Offline)\"\n",
                "6. Test with plant images!\n",
                "\n",
                "### Model Performance:\n",
                "- Expected accuracy: **~95%**\n",
                "- Browser inference time: **<500ms**\n",
                "- Model size: **~15MB**"
            ],
            "metadata": {
                "id": "done"
            }
        }
    ]
}